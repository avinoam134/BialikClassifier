{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adjusted_rand_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trankit import Pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline('hebrew')\n",
    "\n",
    "with open(\"./../Poems_And_Outputs/Poems_Unparsed.JSON\", \"r\", encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "poems = [poem[\"content\"] for poem in data]\n",
    "names = [poem[\"poem\"] for poem in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "הכנת אוסף מילות מפתח מכל שיר (בלי \"וגם\" וכאלה)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'poems' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m poems_posed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,poem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mpoems\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m      4\u001b[0m       poems_posed\u001b[38;5;241m.\u001b[39mappend(p(poem))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'poems' is not defined"
     ]
    }
   ],
   "source": [
    "poems_posed = []\n",
    "for i,poem in enumerate(poems):\n",
    "    if i<100:\n",
    "      poems_posed.append(p(poem))\n",
    "    if i==0:\n",
    "        print(poems_posed[0])\n",
    "\n",
    "with open(\"./../Poems_And_Outputs/all_songs_processed.JSON\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(poems_posed, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    with open(\"./../Poems_And_Outputs/all_songs_processed.JSON\", 'r', encoding='utf-8') as f:\n",
    "        songs_parsed = json.load(f)\n",
    "        res = []\n",
    "        for song in songs_parsed:\n",
    "            res.append(_tokenize(song))\n",
    "        return res\n",
    "\n",
    "def _tokenize(song_dict):\n",
    "    tokens = []\n",
    "    if isinstance(song_dict, dict):\n",
    "        for key, value in song_dict.items():\n",
    "            if key == 'tokens':\n",
    "                tokens.extend(get_tokens(song_dict[\"tokens\"]))\n",
    "            elif isinstance(value, dict):\n",
    "                tokens.extend(_tokenize(value))\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        tokens.extend(_tokenize(item))\n",
    "    return tokens\n",
    "\n",
    "def get_tokens(tokens):\n",
    "    stop_words_types = [\"PUNCT\", \"PRON\", \"ADP\",\"DET\", \"CCONJ\", \"SCONJ\", \"PART\", \"SYM\", \"X\", \"NUM\"]\n",
    "    included_types = [\"NOUN\", \"VERB\"]\n",
    "    tokens_from_list = []\n",
    "    for token in tokens:\n",
    "        if \"upos\" not in token and \"expanded\" in token:\n",
    "            token[\"upos\"] = token[\"expanded\"][0][\"upos\"]\n",
    "            token[\"lemma\"] = token[\"expanded\"][0][\"lemma\"]\n",
    "        if \"upos\" in token and token[\"upos\"] in included_types:\n",
    "            tokens_from_list.append(token[\"lemma\"])\n",
    "    return tokens_from_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "אימון המודל על מילות מפתח מכל אוספי השירים"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_processed = tokenize()\n",
    "poems_processed = [\" \".join(poem) for poem in poems_processed]\n",
    "x_train, x_hold = train_test_split(poems_processed, test_size=0.3, random_state=111)\n",
    "vectorizer_tf = TfidfVectorizer(max_df=0.7, min_df=2,max_features=10000, use_idf=False, norm=None)\n",
    "vectorizer_tf.lowercase = False\n",
    "tf_vectors = vectorizer_tf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "זה הריבויים של כל מילת מפתח שנבחרה בכל שיר:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 2., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectors.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "וזה המילים שייצאו:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__', 'אב', 'אבא', 'אבד', 'אביב', 'אבך', 'אבן', 'אבר', 'אגדה',\n",
       "       'אדם', 'אדמה', 'אדן', 'אדע', 'אדרה', 'אהב', 'אהבה', 'אהה', 'אהל',\n",
       "       'און', 'אוצר', 'אור', 'אורה', 'אורך', 'אורם', 'אות', 'אזוב', 'אזן',\n",
       "       'אח', 'אחז', 'אחיך', 'אחים', 'אחרית', 'איבד', 'אין', 'איש', 'אישר',\n",
       "       'אכל', 'אל', 'אלהים', 'אלון', 'אלם', 'אם', 'אמונה', 'אמן', 'אמר',\n",
       "       'אמת', 'אנחה', 'אספה', 'אף', 'אפון', 'אפיק', 'אפך', 'אפס', 'אצא',\n",
       "       'אצבע', 'ארא', 'ארב', 'ארג', 'ארון', 'ארך', 'ארץ', 'אש', 'אשא',\n",
       "       'אשנב', 'אשר', 'בא', 'בדק', 'ביטח', 'ביקר', 'ביקש', 'בית', 'בכה',\n",
       "       'בכי', 'בל', 'בלב', 'בן', 'בסתר', 'בעב', 'בער', 'בקר', 'ברזל',\n",
       "       'ברך', 'ברכה', 'בשר', 'בת', 'גאלה', 'גב', 'גבול', 'גבעת', 'גבר',\n",
       "       'גג', 'גדל', 'גדר', 'גוון', 'גויל', 'גוים', 'גוף', 'גופה', 'גחל',\n",
       "       'גחלה', 'גיל', 'גל', 'גלגל', 'גלה', 'גלות', 'גמל', 'גן', 'גנב',\n",
       "       'גנוז', 'גע', 'געגוע', 'גף', 'גפה', 'דבר', 'דום', 'דומייה', 'דור',\n",
       "       'דיבר', 'דלות', 'דם', 'דמדום', 'דמות', 'דמם', 'דממה', 'דמעה', 'דע',\n",
       "       'דעה', 'דעך', 'דעתם', 'דקה', 'דרור', 'דרך', 'האיר', 'האית',\n",
       "       'האציל', 'הבא', 'הבהיק', 'הביא', 'הביט', 'הבין', 'הבקיע', 'הברכה',\n",
       "       'הגיד', 'הגיה', 'הגיון', 'הגיע', 'הד', 'הויי', 'הוליך', 'הום',\n",
       "       'הוסיף', 'הועיל', 'הופיע', 'הוציא', 'הוריד', 'הותיר', 'הזדעזע',\n",
       "       'הזהיר', 'החליק', 'החריש', 'הטהר', 'הטל', 'היה', 'היטיב', 'היכל',\n",
       "       'הכה', 'הכיל', 'הכין', 'הכיר', 'הלך', 'המית', 'הסר', 'הסתר',\n",
       "       'העיר', 'הערים', 'הפה', 'הפך', 'הציל', 'הציץ', 'הקים', 'הקיץ',\n",
       "       'הקל', 'הקמה', 'הקץ', 'הקשה', 'הר', 'הראה', 'הרגיז', 'הרגיש',\n",
       "       'הרהור', 'הרים', 'הרס', 'הרקיע', 'השכים', 'השליך', 'השתפך',\n",
       "       'התאפק', 'התבונן', 'התבקע', 'התגלגל', 'התגלה', 'התגנב', 'התדפק',\n",
       "       'התהולל', 'התזכר', 'התחדש', 'התלונן', 'התלקח', 'התלקט', 'התמהם',\n",
       "       'התמלט', 'התנכר', 'התעטף', 'התעלל', 'התערב', 'התפוצץ', 'התפלה',\n",
       "       'התפלל', 'התפלש', 'התקדש', 'התרעלה', 'וי', 'ונה', 'זבוב', 'זה',\n",
       "       'זהב', 'זהבך', 'זהר', 'זות', 'זיז', 'זיכר', 'זכה', 'זכוכית',\n",
       "       'זכות', 'זכר', 'זכרון', 'זלל', 'זמן', 'זמר', 'זמרת', 'זע', 'זעזע',\n",
       "       'זעם', 'זעף', 'זעפה', 'זעת', 'זקן', 'זקנה', 'זר', 'זרח', 'זרע',\n",
       "       'זרק', 'חבר', 'חג', 'חד', 'חדל', 'חדר', 'חוט', 'חז', 'חזון',\n",
       "       'חזיון', 'חזיר', 'חזקן', 'חטט', 'חי', 'חיבא', 'חיד', 'חיה', 'חייך',\n",
       "       'חיים', 'חיל', 'חיק', 'חיקך', 'חיש', 'חישך', 'חישף', 'חכה', 'חכח',\n",
       "       'חל', 'חלב', 'חלום', 'חלון', 'חליפות', 'חלל', 'חלם', 'חלמות',\n",
       "       'חלף', 'חלק', 'חם', 'חמדה', 'חמודה', 'חמלה', 'חן', 'חנות', 'חסד',\n",
       "       'חץ', 'חצות', 'חציר', 'חצץ', 'חרב', 'חרבה', 'חרבות', 'חרד', 'חרדה',\n",
       "       'חרל', 'חרף', 'חרפה', 'חרק', 'חרש', 'חש', 'חשה', 'חשך', 'חשכה',\n",
       "       'חתל', 'חתר', 'טבע', 'טהר', 'טוב', 'טיל', 'טימא', 'טמן', 'טפה',\n",
       "       'טרף', 'יבא', 'יבש', 'יד', 'ידיד', 'ידע', 'יהודי', 'יום', 'יונה',\n",
       "       'יים', 'יישוב', 'יכל', 'ילד', 'ילדות', 'ים', 'יסוד', 'יער', 'יערה',\n",
       "       'יפ', 'יפה', 'יצא', 'יצר', 'יקום', 'ירד', 'יריעה', 'ירק', 'יש',\n",
       "       'ישא', 'ישב', 'ישועה', 'כאב', 'כבד', 'כבה', 'כוח', 'כוכב', 'כוס',\n",
       "       'כחות', 'כיבה', 'כיין', 'כלב', 'כלה', 'כלו', 'כלום', 'כלי', 'כלך',\n",
       "       'כלם', 'כמה', 'כמות', 'כנף', 'כסות', 'כסף', 'כסת', 'כף', 'כפיר',\n",
       "       'כר', 'כרוב', 'כרך', 'כתל', 'כתר', 'לא', 'לב', 'לבב', 'לבי', 'לבך',\n",
       "       'לבכות', 'להב', 'לחישה', 'לחם', 'לחש', 'ליאת', 'ליל', 'לילה',\n",
       "       'למד', 'לפנות', 'לשון', 'מארץ', 'מבט', 'מגדל', 'מוות', 'מולדת',\n",
       "       'מות', 'מותי', 'מזמור', 'מחבא', 'מחה', 'מטה', 'מטמון', 'מטר',\n",
       "       'מידה', 'מים', 'מכת', 'מלא', 'מלאך', 'מלט', 'מנוחה', 'מע', 'מעבר',\n",
       "       'מעלה', 'מעשה', 'מפה', 'מפין', 'מפנים', 'מפרש', 'מצא', 'מצח',\n",
       "       'מצל', 'מקום', 'מקלט', 'מר', 'מראה', 'מרחב', 'מרחק', 'משא', 'משאה',\n",
       "       'משד', 'משואה', 'משורר', 'משנה', 'מת', 'מתוק', 'נא', 'נאד', 'נאדר',\n",
       "       'נאלח', 'נאלם', 'נאמן', 'נביא', 'נבל', 'נבלע', 'נגה', 'נגלה',\n",
       "       'נגע', 'נד', 'נדבה', 'נדד', 'נדוד', 'נדח', 'נדמה', 'נהר', 'נודה',\n",
       "       'נולד', 'נוצץ', 'נושן', 'נזחל', 'נזרק', 'נח', 'נחטף', 'נחל',\n",
       "       'נחלק', 'נחמה', 'נחפז', 'נחשה', 'נחשף', 'נחת', 'נטף', 'נטפה',\n",
       "       'ניגה', 'ניד', 'ניער', 'ניצוץ', 'ניצח', 'נכר', 'נמג', 'נמלט',\n",
       "       'נמצא', 'נמק', 'ננער', 'נס', 'נסה', 'נסוג', 'נע', 'נעוה', 'נעור',\n",
       "       'נעורים', 'נעזב', 'נעכר', 'נעל', 'נעלם', 'נענה', 'נעקר', 'נער',\n",
       "       'נערה', 'נערם', 'נפוץ', 'נפל', 'נפעם', 'נפקד', 'נפרץ', 'נפש',\n",
       "       'נפשי', 'נצב', 'נצבה', 'נצפן', 'נקלה', 'נר', 'נראה', 'נרדם',\n",
       "       'נרות', 'נרים', 'נרקב', 'נשא', 'נשבה', 'נשבר', 'נשיקה', 'נשכח',\n",
       "       'נשמה', 'נשמע', 'נשמת', 'נשן', 'נשף', 'נשפך', 'נשק', 'נשקף', 'נשת',\n",
       "       'נתיב', 'נתכה', 'נתלה', 'נתן', 'נתק', 'נתרוקן', 'סגריר', 'סוד',\n",
       "       'סוף', 'סופת', 'סחף', 'סיפר', 'סלע', 'סנור', 'סף', 'ספיר', 'ספך',\n",
       "       'ספר', 'סר', 'סתר', 'עב', 'עבד', 'עבדה', 'עבר', 'עגלה', 'עד',\n",
       "       'עדיך', 'עדן', 'עודן', 'עוטה', 'עולם', 'עוף', 'עור', 'עז', 'עזב',\n",
       "       'עזז', 'עיל', 'עימד', 'עין', 'עיןך', 'עינה', 'עיניה', 'עיפה',\n",
       "       'עיר', 'על', 'עלה', 'עלום', 'עלטה', 'עליז', 'עם', 'עמד', 'עמדה',\n",
       "       'עמה', 'עמוד', 'עמך', 'עמק', 'ען', 'ענה', 'ענן', 'ענק', 'עפעף',\n",
       "       'עפר', 'עפרות', 'עץ', 'עצב', 'עצם', 'עקב', 'עקרב', 'ער', 'ערב',\n",
       "       'ערבי', 'ערות', 'עריר', 'ערך', 'ערל', 'עשה', 'עשן', 'עת', 'פגר',\n",
       "       'פה', 'פז', 'פזז', 'פחז', 'פחת', 'פטיש', 'פיזז', 'פיך', 'פלח',\n",
       "       'פליט', 'פנה', 'פנות', 'פני', 'פנים', 'פנין', 'פעה', 'פעל', 'פעם',\n",
       "       'פקד', 'פרוטה', 'פרור', 'פרח', 'פרי', 'פרץ', 'פרק', 'פרש', 'פשט',\n",
       "       'פתאם', 'פתה', 'פתח', 'צא', 'צאה', 'צאל', 'צאן', 'צאת', 'צבא',\n",
       "       'צדק', 'צהר', 'צואר', 'צויץ', 'צח', 'צחוק', 'ציהל', 'ציץ', 'ציר',\n",
       "       'צל', 'צלל', 'צללים', 'צלמה', 'צנור', 'צעד', 'צעיף', 'צפה', 'צפון',\n",
       "       'צפעון', 'צפר', 'צפריר', 'צר', 'צרור', 'קבר', 'קדוש', 'קדח', 'קדם',\n",
       "       'קדמה', 'קדמון', 'קדקד', 'קדרות', 'קדש', 'קו', 'קול', 'קולי',\n",
       "       'קולך', 'קום', 'קומה', 'קומם', 'קוץ', 'קור', 'קטרה', 'קין', 'קינה',\n",
       "       'קיפץ', 'קיץ', 'קיצה', 'קיר', 'קלבה', 'קלון', 'קלל', 'קם', 'קן',\n",
       "       'קנה', 'קפן', 'קץ', 'קרא', 'קראן', 'קראש', 'קרבי', 'קרבן', 'קרה',\n",
       "       'קרח', 'קרן', 'קרעה', 'קרץ', 'קרקע', 'קרש', 'קשב', 'קשר', 'ראה',\n",
       "       'ראות', 'ראש', 'ראשך', 'רב', 'רבון', 'רגז', 'רגל', 'רגע', 'רגש',\n",
       "       'רוח', 'רוחה', 'רוחך', 'רום', 'רז', 'רחם', 'רחמים', 'רטב', 'ריח',\n",
       "       'ריחו', 'ריקם', 'רך', 'רכב', 'רמה', 'רמז', 'רנן', 'רסיס', 'רע',\n",
       "       'רעב', 'רעד', 'רעם', 'רענן', 'רץ', 'רצה', 'רקב', 'רקבון', 'רקיע',\n",
       "       'רקם', 'רקע', 'רשף', 'שא', 'שאול', 'שאון', 'שאל', 'שב', 'שבה',\n",
       "       'שבט', 'שבל', 'שבר', 'שד', 'שדה', 'שוטט', 'שורה', 'שח', 'שחוק',\n",
       "       'שחקים', 'שחר', 'שחת', 'שט', 'שטן', 'שטף', 'שיא', 'שיחק', 'שימע',\n",
       "       'שימש', 'שיקע', 'שיר', 'שירה', 'שיתא', 'שכבה', 'שכח', 'שלג',\n",
       "       'שלוה', 'שלום', 'שלומה', 'שלח', 'שלט', 'שם', 'שמיים', 'שמם', 'שמע',\n",
       "       'שמר', 'שמש', 'שמשה', 'שנה', 'שעה', 'שער', 'שפ', 'שפה', 'שפך',\n",
       "       'שפל', 'שפעה', 'שקט', 'שקע', 'שקק', 'שר', 'שריר', 'שתק', 'תבא',\n",
       "       'תבך', 'תבל', 'תדע', 'תהה', 'תהום', 'תהמות', 'תוחלת', 'תולעת',\n",
       "       'תורה', 'תח', 'תחה', 'תחייה', 'תיקע', 'תכלה', 'תל', 'תלא', 'תלה',\n",
       "       'תלתל', 'תם', 'תמה', 'תמח', 'תמצית', 'תנה', 'תנומה', 'תנחום',\n",
       "       'תנחומה', 'תעה', 'תענוג', 'תפוח', 'תפל', 'תפלה', 'תפש', 'תקות',\n",
       "       'תקע', 'תרועה', 'תרועת', 'תשק'], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "אימון מודל שמקשר בין מילות מפתח בשירים השונים ויוצר נושאים על בסיס מילים משותפות:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "lda = decomposition.LatentDirichletAllocation(n_components=6, max_iter=5, learning_method='batch', n_jobs=-1, random_state=111).fit(tf_vectors)\n",
    "W1 = lda.fit_transform(tf_vectors)\n",
    "H1 = lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "זה ההסתברות של כל שיר להיות בנושא מסויים מבין 6 הנושאים:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.82563461e-03, 9.50782989e-01, 9.85082080e-03, 9.82368588e-03,\n",
       "        9.84558205e-03, 9.87128763e-03],\n",
       "       [1.04763938e-03, 9.94754661e-01, 1.04900029e-03, 1.04683214e-03,\n",
       "        1.05059765e-03, 1.05126969e-03],\n",
       "       [2.74391343e-03, 2.74772422e-03, 9.86261027e-01, 2.74570950e-03,\n",
       "        2.75080184e-03, 2.75082367e-03],\n",
       "       [3.09295421e-03, 3.10727180e-03, 3.10948737e-03, 3.10001490e-03,\n",
       "        3.10672367e-03, 9.84483548e-01],\n",
       "       [6.70207864e-03, 6.70031496e-03, 6.70643093e-03, 9.66487849e-01,\n",
       "        6.70398171e-03, 6.69934462e-03],\n",
       "       [5.22929242e-03, 5.22264721e-03, 5.23992969e-03, 9.73817587e-01,\n",
       "        5.24566683e-03, 5.24487720e-03],\n",
       "       [2.69963390e-03, 2.70580268e-03, 2.70603369e-03, 2.70648365e-03,\n",
       "        9.86475776e-01, 2.70626988e-03],\n",
       "       [3.09501449e-03, 3.10132821e-03, 3.10251130e-03, 9.84502349e-01,\n",
       "        3.09903904e-03, 3.09975749e-03],\n",
       "       [3.41662867e-03, 3.42238911e-03, 3.43100356e-03, 3.42264053e-03,\n",
       "        9.82881363e-01, 3.42597538e-03],\n",
       "       [3.63725416e-03, 3.64978593e-03, 5.47656286e-01, 3.64829843e-03,\n",
       "        3.64917939e-03, 4.37759196e-01],\n",
       "       [2.69954560e-03, 2.70454357e-03, 2.70475346e-03, 9.86481833e-01,\n",
       "        2.70279861e-03, 2.70652587e-03],\n",
       "       [5.59233875e-03, 5.61340104e-03, 9.72025242e-01, 5.57429550e-03,\n",
       "        5.58882820e-03, 5.60589413e-03],\n",
       "       [7.31173635e-03, 7.28270381e-03, 7.26926923e-03, 7.27873350e-03,\n",
       "        7.29968056e-03, 9.63557877e-01],\n",
       "       [9.44175369e-01, 1.11726363e-02, 1.11433465e-02, 1.11446130e-02,\n",
       "        1.11948000e-02, 1.11692352e-02],\n",
       "       [9.72071331e-01, 5.58261140e-03, 5.58653581e-03, 5.58840234e-03,\n",
       "        5.58502381e-03, 5.58609596e-03],\n",
       "       [3.29783165e-03, 6.54347126e-02, 3.29453097e-03, 3.31196117e-03,\n",
       "        3.28140371e-03, 9.21379560e-01],\n",
       "       [4.21329532e-03, 4.19060294e-03, 4.19679968e-03, 4.19680528e-03,\n",
       "        4.18998451e-03, 9.79012512e-01],\n",
       "       [2.74942515e-03, 4.90580195e-01, 4.98420183e-01, 2.74912323e-03,\n",
       "        2.75204449e-03, 2.74902948e-03],\n",
       "       [1.11661892e-02, 1.11822520e-02, 1.12621450e-02, 1.12054706e-02,\n",
       "        1.11602762e-02, 9.44023667e-01],\n",
       "       [1.19300563e-02, 1.20797078e-02, 9.39865234e-01, 1.20572617e-02,\n",
       "        1.20641033e-02, 1.20036368e-02],\n",
       "       [5.61655053e-03, 5.60420652e-03, 5.59123278e-03, 9.71987457e-01,\n",
       "        5.58782167e-03, 5.61273174e-03],\n",
       "       [5.24545049e-03, 9.73723465e-01, 5.25412127e-03, 5.25730744e-03,\n",
       "        5.26967307e-03, 5.24998250e-03],\n",
       "       [2.45821838e-03, 9.87685927e-01, 2.46767881e-03, 2.46461183e-03,\n",
       "        2.46106428e-03, 2.46249975e-03],\n",
       "       [1.11579354e-02, 1.11628589e-02, 1.11556114e-02, 9.44200254e-01,\n",
       "        1.11703730e-02, 1.11529678e-02],\n",
       "       [1.26930261e-03, 9.93647799e-01, 1.27142621e-03, 1.26943560e-03,\n",
       "        1.26952824e-03, 1.27250798e-03],\n",
       "       [2.55867860e-01, 6.39735321e-04, 7.41570002e-01, 6.40264487e-04,\n",
       "        6.40808619e-04, 6.41329838e-04],\n",
       "       [2.56784405e-01, 9.39428648e-04, 9.38607388e-04, 9.36251359e-04,\n",
       "        7.39460650e-01, 9.40656836e-04],\n",
       "       [5.77455577e-03, 5.78564179e-03, 9.71091097e-01, 5.78967940e-03,\n",
       "        5.76664738e-03, 5.79237900e-03],\n",
       "       [2.23244256e-03, 2.23648052e-03, 2.24194781e-03, 2.24106604e-03,\n",
       "        2.24127052e-03, 9.88806793e-01],\n",
       "       [9.88375766e-01, 2.32678623e-03, 2.32688573e-03, 2.32313968e-03,\n",
       "        2.32256900e-03, 2.32485291e-03],\n",
       "       [1.99464685e-03, 9.90013739e-01, 1.99760839e-03, 1.99347894e-03,\n",
       "        1.99542968e-03, 2.00509701e-03],\n",
       "       [9.63566713e-01, 7.26753353e-03, 7.28549083e-03, 7.30842016e-03,\n",
       "        7.28286808e-03, 7.28897430e-03],\n",
       "       [2.92967829e-03, 2.94016412e-03, 9.85313128e-01, 2.93792781e-03,\n",
       "        2.93783410e-03, 2.94126738e-03],\n",
       "       [1.59738972e-03, 1.59617243e-03, 1.59688066e-03, 1.59955580e-03,\n",
       "        1.59480980e-03, 9.92015192e-01],\n",
       "       [2.37322326e-03, 2.36542443e-03, 9.88172589e-01, 2.36098920e-03,\n",
       "        2.36046174e-03, 2.36731188e-03],\n",
       "       [2.33301973e-01, 1.46536773e-03, 1.46058579e-03, 3.06003960e-01,\n",
       "        1.46153784e-03, 4.56306576e-01],\n",
       "       [5.07843082e-03, 5.08760636e-03, 5.08717142e-03, 9.74518701e-01,\n",
       "        5.12857787e-03, 5.09951213e-03],\n",
       "       [1.77811338e-03, 1.78644550e-03, 1.78366591e-03, 1.78289870e-03,\n",
       "        1.78483528e-03, 9.91084041e-01],\n",
       "       [1.95643003e-03, 1.94812838e-03, 1.95036764e-03, 1.95165801e-03,\n",
       "        9.90244483e-01, 1.94893258e-03],\n",
       "       [4.92415370e-03, 4.95347826e-03, 4.93688126e-03, 4.92359185e-03,\n",
       "        4.92209850e-03, 9.75339796e-01],\n",
       "       [1.65928040e-03, 9.91692469e-01, 1.66091232e-03, 1.66145156e-03,\n",
       "        1.66188926e-03, 1.66399705e-03],\n",
       "       [1.04680590e-02, 1.05266237e-02, 9.47563595e-01, 1.04794369e-02,\n",
       "        1.04819706e-02, 1.04803149e-02],\n",
       "       [8.58699116e-04, 8.60070130e-04, 8.60975394e-04, 8.60175438e-04,\n",
       "        8.59610876e-04, 9.95700469e-01],\n",
       "       [4.78744285e-03, 4.79222078e-03, 9.76044546e-01, 4.77625233e-03,\n",
       "        4.80193762e-03, 4.79760075e-03],\n",
       "       [8.01695153e-03, 8.00309363e-03, 8.01145298e-03, 9.60016869e-01,\n",
       "        7.96823894e-03, 7.98339416e-03],\n",
       "       [2.29772881e-03, 2.29572934e-03, 2.29895980e-03, 2.29376484e-03,\n",
       "        2.29583049e-03, 9.88517987e-01],\n",
       "       [3.56916291e-03, 3.56709346e-03, 9.82136802e-01, 3.57367920e-03,\n",
       "        3.57620232e-03, 3.57705994e-03],\n",
       "       [1.05260733e-02, 9.47456799e-01, 1.05419466e-02, 1.05030067e-02,\n",
       "        1.05182461e-02, 1.04539285e-02],\n",
       "       [2.02698011e-03, 2.02056642e-03, 2.02665197e-03, 2.03153004e-03,\n",
       "        2.02157741e-03, 9.89872694e-01],\n",
       "       [1.94935437e-03, 1.95286769e-03, 9.90250636e-01, 1.94884853e-03,\n",
       "        1.94844918e-03, 1.94984432e-03],\n",
       "       [9.86713586e-01, 2.65755730e-03, 2.66394141e-03, 2.65348539e-03,\n",
       "        2.65757931e-03, 2.65385015e-03],\n",
       "       [2.06616403e-03, 2.07377182e-03, 2.06994643e-03, 2.06645226e-03,\n",
       "        2.07211601e-03, 9.89651549e-01],\n",
       "       [9.53443108e-01, 9.29277261e-03, 9.31814957e-03, 9.29137934e-03,\n",
       "        9.32185009e-03, 9.33273997e-03],\n",
       "       [3.80644564e-03, 3.80664658e-03, 3.82529322e-03, 9.80938151e-01,\n",
       "        3.81141370e-03, 3.81204980e-03],\n",
       "       [1.90429055e-03, 1.90298439e-03, 1.90452772e-03, 1.90368831e-03,\n",
       "        9.90473714e-01, 1.91079521e-03],\n",
       "       [4.08184823e-03, 4.08109320e-03, 4.08313500e-03, 4.07896624e-03,\n",
       "        9.79592573e-01, 4.08238428e-03],\n",
       "       [1.20273288e-02, 5.41615692e-01, 1.19600102e-02, 4.10297055e-01,\n",
       "        1.20785305e-02, 1.20213832e-02],\n",
       "       [2.11755606e-03, 2.11918199e-03, 2.12161266e-03, 9.89402482e-01,\n",
       "        2.11738844e-03, 2.12177881e-03],\n",
       "       [3.16498293e-03, 3.16497917e-03, 9.84180365e-01, 3.16246598e-03,\n",
       "        3.15613512e-03, 3.17107221e-03],\n",
       "       [1.94262386e-03, 1.94936381e-03, 1.95076721e-03, 1.94826798e-03,\n",
       "        9.90259352e-01, 1.94962515e-03],\n",
       "       [9.81364057e-01, 3.72402061e-03, 3.72747450e-03, 3.72513000e-03,\n",
       "        3.72808709e-03, 3.73123061e-03],\n",
       "       [2.30899190e-03, 4.24996905e-01, 2.30558915e-03, 5.65780416e-01,\n",
       "        2.30564086e-03, 2.30245687e-03],\n",
       "       [5.39182648e-03, 5.40672367e-03, 5.41323403e-03, 5.40916623e-03,\n",
       "        5.41310434e-03, 9.72965945e-01],\n",
       "       [3.28635039e-03, 3.28348392e-03, 9.83559424e-01, 3.28753138e-03,\n",
       "        3.29942235e-03, 3.28378816e-03],\n",
       "       [3.80859116e-03, 9.80963028e-01, 3.80983015e-03, 3.79720834e-03,\n",
       "        3.80386869e-03, 3.81747366e-03],\n",
       "       [8.39434550e-02, 8.34417069e-02, 8.40114995e-02, 8.33337110e-02,\n",
       "        5.81856164e-01, 8.34134638e-02],\n",
       "       [1.28494743e-02, 1.29510474e-02, 9.35488658e-01, 1.28705488e-02,\n",
       "        1.29298662e-02, 1.29104052e-02],\n",
       "       [9.82910483e-01, 3.42210107e-03, 3.41768449e-03, 3.41378419e-03,\n",
       "        3.41866681e-03, 3.41728028e-03],\n",
       "       [8.38701511e-03, 8.41706279e-03, 8.38099692e-03, 8.37909984e-03,\n",
       "        8.37710302e-03, 9.58058722e-01],\n",
       "       [9.76722839e-01, 4.64426991e-03, 4.64857445e-03, 4.65801034e-03,\n",
       "        4.66798686e-03, 4.65831927e-03]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "וזה 6 הנושאים:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10\n",
    "vocab = np.array(vectorizer_tf.get_feature_names_out())\n",
    "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "topic_words = ([top_words(t) for t in H1])\n",
    "topics = [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['עולם אין יום אלהים רוח פה עב נפש אם אמר',\n",
       " 'אין נפש רוח עין קול חיים יום אלהים אבד עם',\n",
       " 'אור נפש עין לב שמש יד יום בן ראש חיים',\n",
       " 'אור נפל בא קול קרן נפש יד הלך לב ילד',\n",
       " 'חיים לב עין פנים ראה כוכב אור בן היה נפש',\n",
       " 'איש עין חיים רוח דמעה ידע עולם קול דם נפש']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
