{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708726546669,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"h0cP-Zjo9aoJ","outputId":"2f5d5fd2-edb2-47fa-fbfd-6fde1afbb97c"},"outputs":[{"data":{"text/plain":["list"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","\n","# Open the JSON file\n","with open('./../Poems_And_Outputs/Poems_Unparsed.JSON' , 'r', encoding='utf-8') as f:\n","    data = json.load(f)\n","\n","datasongs = []\n","datalabels = []\n","\n","for song in data:\n","  if not song['year'] == \"\":\n","    datasongs.append(song['content'])\n","    if int(song['year']) < 1900:\n","      datalabels.append(0)\n","    elif int(song['year']) < 1910:\n","      datalabels.append(1)\n","    else:\n","      datalabels.append(2)\n"]},{"cell_type":"markdown","metadata":{"id":"nIPWq6wG_pzV"},"source":["### **Decision** **Trees**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1778,"status":"ok","timestamp":1708725289077,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"xuUySnqJ9gbv","outputId":"f83f9642-47f9-4362-c0ba-1959fe133e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7272727272727273\n","Final Accuracy: 0.7272727272727273\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = DecisionTreeClassifier()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"HYFkCuUZ_nLY"},"source":["### **Random** **Forests**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1708725445556,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"Gfdszc5T-RWJ","outputId":"96d5de8b-eb75-4677-eb9b-63dbc1b61b75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7272727272727273\n","Final Accuracy: 0.7272727272727273\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = RandomForestClassifier()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"f-zM4fNO_jTG"},"source":[]},{"cell_type":"markdown","metadata":{"id":"3k-rDMnb_hSk"},"source":["### **Gradient Boosting Machines (GBM)**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6026,"status":"ok","timestamp":1708725539249,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"TP-woJrf-dj9","outputId":"c9bc3f3f-4df7-4270-b70b-0ba35322058a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8636363636363636\n","Final Accuracy: 0.8636363636363636\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","N_ESTIMATORS = 100\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = GradientBoostingClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"YGIMnHN-_YsT"},"source":["### **Support Vector Machines (SVM)**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1708725582888,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"6wusfQSB-zFe","outputId":"595956e5-3881-4b24-911b-790483c39aff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6363636363636364\n","Final Accuracy: 0.6363636363636364\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = SVC(random_state=RANDOM_STATE)\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"1SDok-5d_OD8"},"source":["### **Naive Bayes**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708725643287,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"-HJS6_l-_BmI","outputId":"880c77e6-4119-4b41-d45b-b659a8d10b04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5909090909090909\n","Final Accuracy: 0.5909090909090909\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = MultinomialNB()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP1sNzCoppIyq6vLJcoddgn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
