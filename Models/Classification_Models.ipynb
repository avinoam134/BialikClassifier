{"cells":[{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708726546669,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"h0cP-Zjo9aoJ","outputId":"2f5d5fd2-edb2-47fa-fbfd-6fde1afbb97c"},"outputs":[],"source":["import json\n","\n","# Open the JSON file\n","with open('./../Poems_And_Outputs/Poems_Unparsed.JSON' , 'r', encoding='utf-8') as f:\n","    data = json.load(f)\n","\n","datasongs = []\n","datalabels = []\n","eval_data = []\n","eval_names = []\n","\n","for song in data:\n","  if not song['year'] == \"\":\n","    datasongs.append(song['content'])\n","    if int(song['year']) < 1900:\n","      datalabels.append(0)\n","    elif int(song['year']) < 1909:\n","      datalabels.append(1)\n","    else:\n","      datalabels.append(2)\n","      \n","  elif song[\"published\"]==\"no\":\n","    eval_data.append(song['content'])\n","    eval_names.append(song['poem'])\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"nIPWq6wG_pzV"},"source":["### **Decision** **Trees**"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1778,"status":"ok","timestamp":1708725289077,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"xuUySnqJ9gbv","outputId":"f83f9642-47f9-4362-c0ba-1959fe133e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8181818181818182\n","Final Accuracy: 0.8181818181818182\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = DecisionTreeClassifier()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def labels_to_years(labels):\n","    res = []\n","    for label in labels:\n","        if label == 0:\n","            res.append(\"-1900\")\n","        elif label == 1:\n","            res.append(\"1900-1909\")\n","        else:\n","            res.append(\"1910+\")\n","    return res"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["predictions = labels_to_years(classifier.predict(vectorizer.transform(eval_data)))\n","out = list(zip(eval_names, predictions))\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["[(\"קטעים של 'שירי עם' ב\", '1900-1909'),\n"," (\"קטעים של 'שירי עם' ג\", '1900-1909'),\n"," ('למי אוצרות קורח', '1900-1909'),\n"," ('התעוני חרבוני צהרים', '1900-1909'),\n"," ('משירי עם  1', '1900-1909'),\n"," ('משירי עם 2', '1900-1909'),\n"," ('משירי עם 3', '1900-1909'),\n"," ('משירי עם 4', '1900-1909'),\n"," ('משירי עם 5', '1900-1909'),\n"," ('אברם אברם', '1900-1909'),\n"," ('למנצח על הנגינות', '1900-1909'),\n"," ('דבורת הזהב', '-1900'),\n"," ('רסיסים א', '1900-1909'),\n"," ('רסיסים ב', '1900-1909'),\n"," ('רסיסים ג', '1900-1909'),\n"," ('רסיסים ד', '1900-1909'),\n"," ('רסיסים ה', '1900-1909'),\n"," ('רסיסים ו', '1900-1909'),\n"," ('רסיסים ז', '1900-1909'),\n"," ('אהה, לו ידעתי איך אשכם', '1900-1909')]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["out[40:]"]},{"cell_type":"markdown","metadata":{"id":"HYFkCuUZ_nLY"},"source":["### **Random** **Forests**"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1708725445556,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"Gfdszc5T-RWJ","outputId":"96d5de8b-eb75-4677-eb9b-63dbc1b61b75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8181818181818182\n","Final Accuracy: 0.8181818181818182\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = RandomForestClassifier()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["predictions = labels_to_years(classifier.predict(vectorizer.transform(eval_data)))\n","out = list(zip(eval_names, predictions))"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["[(\"בכרכי ים (חלק ב' של השיר “ילדות”)\", '1900-1909'),\n"," ('מחוץ לעיר', '1900-1909'),\n"," ('אוי מלב בוקעת', '1900-1909'),\n"," ('אחים לצרה', '-1900'),\n"," ('חזק ואמץ', '1900-1909'),\n"," ('עומד ומפשפש', '1900-1909'),\n"," ('האופה והקטף', '1900-1909'),\n"," ('עבר הקיץ', '-1900'),\n"," ('אל תראו', '1900-1909'),\n"," (\" קטעים של 'שירי עם' א\", '1900-1909'),\n"," (\"קטעים של 'שירי עם' ב\", '1900-1909'),\n"," (\"קטעים של 'שירי עם' ג\", '1900-1909'),\n"," ('למי אוצרות קורח', '1900-1909'),\n"," ('התעוני חרבוני צהרים', '1900-1909'),\n"," ('משירי עם  1', '1900-1909'),\n"," ('משירי עם 2', '1900-1909'),\n"," ('משירי עם 3', '1900-1909'),\n"," ('משירי עם 4', '1900-1909'),\n"," ('משירי עם 5', '1900-1909'),\n"," ('אברם אברם', '1900-1909'),\n"," ('למנצח על הנגינות', '1900-1909'),\n"," ('דבורת הזהב', '1900-1909'),\n"," ('רסיסים א', '1900-1909'),\n"," ('רסיסים ב', '1900-1909'),\n"," ('רסיסים ג', '1900-1909'),\n"," ('רסיסים ד', '1900-1909'),\n"," ('רסיסים ה', '1900-1909'),\n"," ('רסיסים ו', '1900-1909'),\n"," ('רסיסים ז', '1900-1909'),\n"," ('אהה, לו ידעתי איך אשכם', '1900-1909')]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["out[30:]"]},{"cell_type":"markdown","metadata":{"id":"f-zM4fNO_jTG"},"source":[]},{"cell_type":"markdown","metadata":{"id":"3k-rDMnb_hSk"},"source":["### **Gradient Boosting Machines (GBM)**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6026,"status":"ok","timestamp":1708725539249,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"TP-woJrf-dj9","outputId":"c9bc3f3f-4df7-4270-b70b-0ba35322058a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8636363636363636\n","Final Accuracy: 0.8636363636363636\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","N_ESTIMATORS = 100\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = GradientBoostingClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"YGIMnHN-_YsT"},"source":["### **Support Vector Machines (SVM)**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1708725582888,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"6wusfQSB-zFe","outputId":"595956e5-3881-4b24-911b-790483c39aff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6363636363636364\n","Final Accuracy: 0.6363636363636364\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = SVC(random_state=RANDOM_STATE)\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"1SDok-5d_OD8"},"source":["### **Naive Bayes**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708725643287,"user":{"displayName":"רוני ניסן","userId":"16083910560667753644"},"user_tz":-120},"id":"-HJS6_l-_BmI","outputId":"880c77e6-4119-4b41-d45b-b659a8d10b04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5909090909090909\n","Final Accuracy: 0.5909090909090909\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","\n","# Global hyperparameters\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 50\n","\n","def train_classifier(songs, labels):\n","    # Splitting the data into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(songs, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n","\n","    # Vectorizing the text data\n","    vectorizer = CountVectorizer()\n","    X_train_vec = vectorizer.fit_transform(X_train)\n","    X_test_vec = vectorizer.transform(X_test)\n","\n","    # Creating and training the classifier\n","    classifier = MultinomialNB()\n","    classifier.fit(X_train_vec, y_train)\n","\n","    return classifier, vectorizer, X_test_vec, y_test\n","\n","def evaluate_classifier(classifier, X_test_vec, y_test):\n","    # Making predictions\n","    predictions = classifier.predict(X_test_vec)\n","\n","    # Evaluating the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(\"Accuracy:\", accuracy)\n","    return accuracy\n","\n","# Sample data\n","songs = datasongs\n","labels = datalabels\n","\n","# Train the classifier\n","classifier, vectorizer, X_test_vec, y_test = train_classifier(songs, labels)\n","\n","# Evaluate the classifier\n","accuracy = evaluate_classifier(classifier, X_test_vec, y_test)\n","\n","# Print accuracy\n","print(\"Final Accuracy:\", accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP1sNzCoppIyq6vLJcoddgn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
